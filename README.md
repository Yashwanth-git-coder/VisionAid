# VisionAid: Empowering Accessibility Through Object Detection

VisionAid is a Python-based project aimed at improving accessibility for visually impaired individuals by providing real-time object detection using the YOLO algorithm. This project leverages the power of computer vision technologies along with the capabilities of the LLM (Language Model) API, Tkinter, and OpenCV to create an intuitive and user-friendly interface.

## Features
- **Real-time Object Detection**: Utilizes the YOLO (You Only Look Once) algorithm for efficient and accurate object detection in real-time.
- **Voice Feedback**: Integrates the LLM API to provide voice feedback, enabling users to interact with the detected objects through spoken descriptions.
- **User Interface with Tkinter**: Implements a graphical user interface (GUI) using Tkinter, offering an intuitive interaction platform for users.
- **OpenCV Integration**: Harnesses the power of OpenCV for image processing and handling, ensuring seamless integration with the object detection pipeline.

## How it Works
1. **Object Detection**: The project uses the YOLO algorithm to detect objects in real-time video feed or images.
2. **Object Classification**: Detected objects are classified and processed to provide relevant information about their identity and location.
3. **Voice Feedback**: Utilizing the LLM API, the system generates spoken descriptions of the detected objects, providing auditory feedback to the user.
4. **User Interaction**: The Tkinter-based GUI allows users to interact with the system, providing input and receiving output through a user-friendly interface.

## Installation
1. Clone the repository:

    https://github.com/Yashwanth-git-coder/VisionAid.git

2. Install dependencies:

    pip install -r requirements.txt


## Usage
1. Run the application:
    python main.py

2. Follow the instructions on the GUI to interact with the object detection system.
3. Enjoy enhanced accessibility through real-time object detection and voice feedback!

## Contributing
Contributions are welcome! If you'd like to contribute to this project, please fork the repository and submit a pull request with your changes.

## License
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
